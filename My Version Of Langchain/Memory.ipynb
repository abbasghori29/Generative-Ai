{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cf9393-edbe-4365-b85f-08a176a93968",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9fc6a-3c3c-4a6c-87b6-bdfcac126aa7",
   "metadata": {},
   "source": [
    "## API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1097ea-d1fa-400e-aed7-0f9e23de7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_API_KEY'] = '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'\n",
    "os.environ[\"Google_API_KEY\"]='AIzaSyDpbCpx4NQj9zrHZBg6zLPRB7oOD_IhsZA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a12e32-e798-44b9-bf08-03c6c57dc251",
   "metadata": {},
   "source": [
    "## Setting Up Google Gen Ai Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5510b738-283c-4115-9100-db2d8681f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "api_key='AIzaSyDpbCpx4NQj9zrHZBg6zLPRB7oOD_IhsZA'\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"models/text-bison-001\", google_api_key=api_key , temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a93cf-b395-4306-b854-4cea96de6fa7",
   "metadata": {},
   "source": [
    "# Conversation Buffer Memory: \n",
    "## Setting up conversation chain with Langchain \"Conversation Buffer Memory\" to save our conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3779d12-deb1-43f9-b9e0-88257058f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook shows how to use ConversationBufferMemory. This memory allows for storing messages and then extracts the messages in a variable.\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True   # verbose=True so we can see the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0677cfad-991a-4d58-95ef-d05feb0ff500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Abbas Ghori\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi Abbas Ghori, nice to meet you. How are you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Abbas Ghori\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8563bcfc-159e-4f46-9e47-ae2200ea40f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Abbas Ghori\n",
      "AI: Hi Abbas Ghori, nice to meet you. How are you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0625ce2e-d4b3-46fc-b77d-ec044cb2287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Abbas Ghori\n",
      "AI: Hi Abbas Ghori, nice to meet you. How are you today?\n",
      "Human: What is 1+1?\n",
      "AI: 2\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Abbas Ghori'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eccd6b1f-38c6-44a5-bf08-b6a16cb9f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Abbas Ghori\n",
      "AI: Hi Abbas Ghori, nice to meet you. How are you today?\n",
      "Human: What is 1+1?\n",
      "AI: 2\n",
      "Human: what is my name?\n",
      "AI: Abbas Ghori\n"
     ]
    }
   ],
   "source": [
    "# To see full conversation memory\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf062a-00f5-4000-9063-bb104e80275a",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory: \n",
    "* ConversationBufferWindowMemory keeps a list of the interactions of the conversation over time. It only uses the last K interactions.\n",
    "  This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd822289-4c07-4a6e-aeab-fdbccadd2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory(k=1)   # here, k=1 means remember only one conversation exchange  \n",
    "\n",
    "# making conversation chain by using ConversationBufferWindowMemory as memory\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True   # verbose=True so we can see the prompt \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d69bc193-cab9-4a82-b082-962a08fa66dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Abbas Ghori\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Abbas Ghori, it is nice to meet you.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Abbas Ghori\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac691e1c-a17b-47b3-8803-1f952272aae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Abbas Ghori\n",
      "AI: Hello Abbas Ghori, it is nice to meet you.\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3e7ec16-eef5-4a80-82ba-c3ddc9c5e0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 2\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know your name.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")  \n",
    "# now you can see in output it remembered only 1 conversation exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d3517-9f49-4d12-b55a-40ee8567537d",
   "metadata": {},
   "source": [
    "# Conversation Token Buffer\r",
    "*\n",
    "ConversationTokenBufferMemory keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97749f6b-2a79-4f9f-ae8c-98746ae29bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c43f24-9220-4d9f-9e43-ec2e9f7690b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387fc5c5-1995-4994-906a-a29e38f9e7f2",
   "metadata": {},
   "source": [
    "# Conversation Summary Buffer\r",
    "*\n",
    "ConversationSummaryBufferMemory combines the two ideas. It keeps a buffer of recent interactions in memory,\n",
    " but rather than just completely flushing old interactions it compiles them into a summary and uses both\n",
    "* It uses token length rather than number of interactions to determine when to flush interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524e34f-bd50-4642-8012-7c41daaa83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d7ce0-809f-42c6-bd67-6e4fda31600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
